{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/miniconda3/envs/vfm_3wdataset/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.outliers import ArbitraryOutlierCapper\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 15\n",
    "matplotlib.rcParams['lines.markersize'] = 8.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3W Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3W dataset is a collection of sensor measurements gathered from real-world offshore oil well operations, supplemented by software-simulated data and hand-crafted synthetic data. It includes eight types of abnormal events.\n",
    "\n",
    "The data is organized into separate folders for each type of event, with each individual data acquisition session saved as a comma-separated value (CSV) file. These sessions capture sensor measurements recorded over time. The files are named according to their data source (real, simulated, or synthetic), followed by sequential numbering. For real events, a timestamp is also included in the file name.\n",
    "\n",
    "Each file represents an instance of a type of abnormal event and typically contains the entire signal, starting from normal operation, progressing through the transient period, and concluding with the steady-state anomaly. The following table provides a summary of the number of instances available for each abnormal event and its source:\n",
    "\n",
    "<center><img src=\"../figures/instances_3wdataset.png\" width=\"600\" height=\"400\"></center>\n",
    "\n",
    "\n",
    "The following table shows the number of observations (or data points) captured during real events in the dataset. Each event is categorized into three stages: Normal, Transient, and Steady-state.\n",
    "\n",
    "- **Normal**: Period when the system operates without any anomalies.\n",
    "- **Transient**:  Phase where the anomaly begins to develop.\n",
    "- **Steady-state**: Phase where the anomaly has fully manifested and stabilized.\n",
    "\n",
    "\n",
    "<center><img src=\"../figures/nobservations_real_3wdataset.png\" width=\"600\" height=\"400\"></center>\n",
    "\n",
    "## **Observations**\n",
    "\n",
    "1) From tables 1 and 2, we can see that the flow instability event is only represented by real instances and is available just for steady-state signal. In flow instability, the boundaries between normal and abnormal conditions are not clearly defined because the system slowly moves from a stable state to an unstable one. These small changes make it difficult to determine exactly when the anomaly starts.\n",
    "\n",
    "2) From tables 1 and 2, we can see that the Severe Slugging event has data from both simulated and real sources, but for real data, there is only for the steady-state. This is because Severe Slugging typically has a sudden onset, meaning the transition from normal operation to slugging occurs abruptly without a gradual or easily detectable progression. As a result, the dataset captures only the fully developed, steady-state phase of the fault, where the severe slugging has stabilized and is most prominent. The rapid nature of this event makes it difficult to capture any transient period before the fault fully manifests.\n",
    "\n",
    "3) The dataset's class imbalance, where certain events have far fewer instances or observations. This imbalance poses challenges for machine learning, as it can lead to biased models. Therefore, model evaluation requires special consideration, particularly in selecting appropriate metrics like precision, recall, or F1-score to accurately assess performance in the imbalanced data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eight  types of abnormal events (Classes):** \n",
    "\n",
    "0) **Normal**:\n",
    "Naturally flowing wells are those in which the formation pressure is sufficient to produce oil commercially without requiring a pump. Most reservoirs at the initial stage of development have enough pressure for a natural flow and thus require less equipment and automation for control and successful oil and gas production.\n",
    "\n",
    "1) **Abrupt increase in BSW (Basic Sediment and Water)**:\n",
    "Suspended water, sediments and other impurities in the production measured as a percentage of the production stream.The lifecycle of each well contains periods of increasing levels of BSW. However, an unexpected rise indicates a developing production issue, which needs to be remedied quickly.\n",
    "\n",
    "2) **Spurious closure of the DHSV (Downhole Safety Valve)**:\n",
    "The valve isolates wellbore fluids in a catastrophic failure of surface equipment. If the valve fails spuriously without any surface signs, it needs to be reopened; hence, an automatic event identification is essential.\n",
    "\n",
    "3) **Severe slugging**:\n",
    "An event in which large gas bubbles follow a sequence of liquid slugs. It is a cyclical phenomenon that can lead to wellhead and pipeline damage. Hence, it is considered a critical abnormality.\n",
    "\n",
    "4) **Flow instability**:\n",
    "Pressure changes within acceptable thresholds, with differences due to slugging, representing the absence of cyclicity. This event can transform into slugging and then a severe variant, which requires imminent actions. \n",
    "\n",
    "5) **Rapid productivity decline**: \n",
    "Flow loss due to changes in reservoir static pressure, alternating BSW percentage, production viscosity, changes in production line diameter, etc.\n",
    "\n",
    "6) **Sudden restriction in the production choke (PCK)**: \n",
    "Quick restriction in the production choke (PCK) â€“ a term Petrobras uses to indicate issues with a PCK valve installed at the beginning of the production line. Short restrictions might be observed when operated manually due to operational problems that need to be identified and reversed.\n",
    "\n",
    "7) **Scaling in the PCK**:\n",
    "A mineral deposit, which can create a significant restriction or even a plug in the production tubing. Thus, monitoring production choke helps recognise the event and take appropriate actions, such as scale inhibitor injections.\n",
    "\n",
    "8) **Hydrate formation in the production line**:\n",
    "Compounds of complex ions formed by water and other substances at reduced temperatures and high pressure, which might lead to plugging of the pipelines. It is one of the most significant issues in oil and gas production, and it can stop flow for an extended period; hence, it needs to be recognised immediately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Measurements:**\n",
    "\n",
    "**PDG(Permanent Downhole Gauge)**\n",
    "A sensor permanently installed in an oil or gas well, designed to continuously monitor real-time conditions.\n",
    "\n",
    "**TPT(Temperature and Pressure Transducer)**\n",
    "A sensor capable of measuring both temperature and pressure in the system. Located inside the Subsea Christmas Tree\n",
    "\n",
    "**MON-CKP(Upstream Pressure and Temperature Sensor at Production Choke)**\n",
    "A sensor that measures the pressure and temperature of the fluid upstream, or before it flows through the production choke (PCK), a valve used to regulate the flow rate of oil or gas.\n",
    "\n",
    "Note: CKP refers to the production choke, which is typically located on the platform.\n",
    "\n",
    "**JUS-CKP(production choke)**\n",
    "A sensor that measures the temperature of the fluid downstream (after) it has passed through the Production Choke (PCK). The data from this sensor helps assess how pressure changes across the choke affect the temperature of the fluid\n",
    "\n",
    "**JUS-CKGL(Downstream Temperature Sensor at Production Choke)**\n",
    "A sensor that measures the temperature of the fluid downstream, or after it has passed through the production choke (PCK). This data is important for analyzing how pressure reduction across the choke affects fluid temperature and flow characteristics.\n",
    "\n",
    "**QGL(Gas Lift Flow Rate)**\n",
    "Measurement of the flow rate of gas being injected into the well through the gas lift system. Gas lift is a technique used to enhance oil production by reducing the density of the fluid column and enabling easier flow from the reservoir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Features predicting Severe Slugging in binary classification:**\n",
    "\n",
    "\n",
    "- **P-PDG**: Temperature at the PDG (Permanent Downhole Gauge) [ÂºC];\n",
    "\n",
    "- **P-TPT**: Pressure at the TPT (temperature and pressure transducer) [Pa];\n",
    "\n",
    "- **T-TPT**: Temperature at the TPT (temperature and pressure transducer) [ÂºC];\n",
    "\n",
    "- **P-MON-CKP**: Upstream pressure of the PCK (production choke) [Pa];\n",
    "\n",
    "- **T-JUS-CKP**: Downstream temperature of the PCK (production choke) [ÂºC];\n",
    "\n",
    "- **P-JUS-CKGL**: Downstream pressure of the GLCK (gas lift choke) [Pa];\n",
    "\n",
    "- **T-JUS-CKGL**: Downstream temperature of the GLCK (gas lift choke) [ÂºC];\n",
    "\n",
    "- **QGL**: Gas lift flow rate [m3/s];\n",
    "\n",
    "- **class**: Label of the observation;\n",
    "\n",
    "- **id**: instance identifier. Hand-drawn and simulated instances have incremental id. Each real instance has an id generated from its first timestamp.\n",
    "\n",
    "### **Boolean columns to check if the value is missing**\n",
    "\n",
    "- P-PDG__is_missing\n",
    "- P-TPT__is_missing\n",
    "- T-TPT__is_missing\n",
    "- P-MON-CKP__is_missing\n",
    "- T-JUS-CKP__is_missing       \n",
    "- P-JUS-CKGL__is_missing\n",
    "- T-JUS-CKGL__is_missing\n",
    "- QGL__is_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Binary Classification for Severe Slugging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(download_dir, positive_event='3'):\n",
    "    addresses, instances, events, y = [], [], [], []\n",
    "    \n",
    "    for root, dirs, files in os.walk(download_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                address = os.path.join(root, file)  # Full file path\n",
    "                instance = file  # The file name itself is the instance\n",
    "                event = root.split('/')[-1]  # Event is the directory (e.g., '0', '3', etc.)\n",
    "                y_ = '1' if event == positive_event else '0'\n",
    "                \n",
    "                addresses.append(address)\n",
    "                instances.append(instance)\n",
    "                events.append(event)\n",
    "                y.append(y_)\n",
    "    sorted_data = sorted(zip(addresses, instances, events, y), key=lambda x: x[0])\n",
    "    addresses, instances, events, y = zip(*sorted_data)\n",
    "    \n",
    "    return list(addresses), list(instances), list(events), list(y)\n",
    "\n",
    "download_dir = os.path.expanduser('~/GitHub/vfm_3wdataset/data/public')\n",
    "addresses, instances, events, y = load_metadata(download_dir, positive_event='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Instance</th>\n",
       "      <th>Event</th>\n",
       "      <th>Class</th>\n",
       "      <th>Set</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/marcos/GitHub/vfm_3wdataset/data/public/...</td>\n",
       "      <td>SIMULATED_00067.csv</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/marcos/GitHub/vfm_3wdataset/data/public/...</td>\n",
       "      <td>SIMULATED_00041.csv</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/marcos/GitHub/vfm_3wdataset/data/public/...</td>\n",
       "      <td>WELL-00005_20170817170000.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/marcos/GitHub/vfm_3wdataset/data/public/...</td>\n",
       "      <td>SIMULATED_00039.csv</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/marcos/GitHub/vfm_3wdataset/data/public/...</td>\n",
       "      <td>WELL-00005_20170402230127.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address  \\\n",
       "0  /home/marcos/GitHub/vfm_3wdataset/data/public/...   \n",
       "1  /home/marcos/GitHub/vfm_3wdataset/data/public/...   \n",
       "2  /home/marcos/GitHub/vfm_3wdataset/data/public/...   \n",
       "3  /home/marcos/GitHub/vfm_3wdataset/data/public/...   \n",
       "4  /home/marcos/GitHub/vfm_3wdataset/data/public/...   \n",
       "\n",
       "                        Instance Event Class    Set  id  \n",
       "0            SIMULATED_00067.csv     3     1  Train   0  \n",
       "1            SIMULATED_00041.csv     3     1  Train   1  \n",
       "2  WELL-00005_20170817170000.csv     0     0  Train   2  \n",
       "3            SIMULATED_00039.csv     3     1  Train   3  \n",
       "4  WELL-00005_20170402230127.csv     0     0  Train   4  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_dir = os.path.expanduser('~/GitHub/vfm_3wdataset/data/public')\n",
    "addresses, instances, events, y = load_metadata(download_dir, positive_event='3')\n",
    "\n",
    "addresses_train, addresses_test, instances_train, \\\n",
    "instances_test, events_train, events_test,\\\n",
    "y_train, y_test = train_test_split(\n",
    "    addresses, instances, events, y,\n",
    "    stratify=y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "data_instances_info = np.column_stack(\n",
    "    [\n",
    "        np.concatenate([addresses_train, addresses_test], axis=0),\n",
    "        np.concatenate([instances_train, instances_test], axis=0),\n",
    "        np.concatenate([events_train, events_test], axis=0),\n",
    "        np.concatenate([y_train, y_test], axis=0),\n",
    "        np.concatenate([['Train']*len(y_train), ['Test']*len(y_test)])\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_metadata = pd.DataFrame(data=data_instances_info, columns=['Address', 'Instance', 'Event', 'Class', 'Set'])\n",
    "df_metadata['id'] = np.arange(df_metadata.shape[0])\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    local_path: str,  \n",
    "    positive_event: str = '3', \n",
    "    periods_undersample: int or str or None = None):\n",
    "\n",
    "    df = pd.read_csv(local_path)\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    df.index = df['timestamp']  \n",
    "    df = df.drop(columns=['timestamp'])  \n",
    "        \n",
    "    df['class'] = df['class'].apply(lambda x: positive_event in str(x)).astype(int)\n",
    "\n",
    "    df = df.ffill().bfill()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'class': \n",
    "            df[f\"{col}__is_missing\"] = 1 if df.isna().sum()[col] == df.shape[0] else 0\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if type(periods_undersample) in [int, str]:\n",
    "        if type(periods_undersample) == int:\n",
    "            periods_undersample = f'{periods_undersample}s'  \n",
    "            \n",
    "        df = df.resample(periods_undersample).last() \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(\n",
    "    addresses, instances, \n",
    "    events, ids,\n",
    "    positive_event: str = '3',\n",
    "    periods_undersample: int or str or None = None\n",
    "):\n",
    "    df_lst = []\n",
    "\n",
    "    for address, instance, event, id_ in zip(addresses, instances, events, ids):\n",
    "        local_file_path = address  \n",
    "\n",
    "        df_temp = load_data(\n",
    "            local_path=local_file_path,\n",
    "            positive_event=positive_event,\n",
    "            periods_undersample=periods_undersample\n",
    "        )\n",
    "        \n",
    "        df_temp['id'] = id_\n",
    "        df_lst.append(df_temp)\n",
    "    \n",
    "    df = pd.concat(df_lst, axis=0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1512455516014235\n",
      "0.14893617021276595\n"
     ]
    }
   ],
   "source": [
    "ids_train = df_metadata[df_metadata.Set == 'Train'].id.values\n",
    "ids_test = df_metadata[df_metadata.Set == 'Test'].id.values\n",
    "\n",
    "mean_y_train = np.mean(np.array(y_train).astype(float))\n",
    "print(mean_y_train)\n",
    "mean_y_test = np.mean(np.array(y_test).astype(float))\n",
    "print(mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "      <th>P-PDG__is_missing</th>\n",
       "      <th>P-TPT__is_missing</th>\n",
       "      <th>T-TPT__is_missing</th>\n",
       "      <th>P-MON-CKP__is_missing</th>\n",
       "      <th>T-JUS-CKP__is_missing</th>\n",
       "      <th>P-JUS-CKGL__is_missing</th>\n",
       "      <th>T-JUS-CKGL__is_missing</th>\n",
       "      <th>QGL__is_missing</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-10 23:49:00</th>\n",
       "      <td>24048050.0</td>\n",
       "      <td>15656440.0</td>\n",
       "      <td>119.3033</td>\n",
       "      <td>10062140.0</td>\n",
       "      <td>90.57189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10 23:50:00</th>\n",
       "      <td>24108100.0</td>\n",
       "      <td>15736100.0</td>\n",
       "      <td>119.2536</td>\n",
       "      <td>10066590.0</td>\n",
       "      <td>90.86570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10 23:51:00</th>\n",
       "      <td>24147830.0</td>\n",
       "      <td>15796550.0</td>\n",
       "      <td>119.2263</td>\n",
       "      <td>10070230.0</td>\n",
       "      <td>91.16160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10 23:52:00</th>\n",
       "      <td>24169110.0</td>\n",
       "      <td>15839570.0</td>\n",
       "      <td>119.2203</td>\n",
       "      <td>10072970.0</td>\n",
       "      <td>91.44675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10 23:53:00</th>\n",
       "      <td>24173070.0</td>\n",
       "      <td>15865880.0</td>\n",
       "      <td>119.2369</td>\n",
       "      <td>10074940.0</td>\n",
       "      <td>91.71573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          P-PDG       P-TPT     T-TPT   P-MON-CKP  T-JUS-CKP  \\\n",
       "timestamp                                                                      \n",
       "2018-04-10 23:49:00  24048050.0  15656440.0  119.3033  10062140.0   90.57189   \n",
       "2018-04-10 23:50:00  24108100.0  15736100.0  119.2536  10066590.0   90.86570   \n",
       "2018-04-10 23:51:00  24147830.0  15796550.0  119.2263  10070230.0   91.16160   \n",
       "2018-04-10 23:52:00  24169110.0  15839570.0  119.2203  10072970.0   91.44675   \n",
       "2018-04-10 23:53:00  24173070.0  15865880.0  119.2369  10074940.0   91.71573   \n",
       "\n",
       "                     P-JUS-CKGL  T-JUS-CKGL  QGL  class  P-PDG__is_missing  \\\n",
       "timestamp                                                                    \n",
       "2018-04-10 23:49:00         0.0         0.0  0.0      1                  0   \n",
       "2018-04-10 23:50:00         0.0         0.0  0.0      1                  0   \n",
       "2018-04-10 23:51:00         0.0         0.0  0.0      1                  0   \n",
       "2018-04-10 23:52:00         0.0         0.0  0.0      1                  0   \n",
       "2018-04-10 23:53:00         0.0         0.0  0.0      1                  0   \n",
       "\n",
       "                     P-TPT__is_missing  T-TPT__is_missing  \\\n",
       "timestamp                                                   \n",
       "2018-04-10 23:49:00                  0                  0   \n",
       "2018-04-10 23:50:00                  0                  0   \n",
       "2018-04-10 23:51:00                  0                  0   \n",
       "2018-04-10 23:52:00                  0                  0   \n",
       "2018-04-10 23:53:00                  0                  0   \n",
       "\n",
       "                     P-MON-CKP__is_missing  T-JUS-CKP__is_missing  \\\n",
       "timestamp                                                           \n",
       "2018-04-10 23:49:00                      0                      0   \n",
       "2018-04-10 23:50:00                      0                      0   \n",
       "2018-04-10 23:51:00                      0                      0   \n",
       "2018-04-10 23:52:00                      0                      0   \n",
       "2018-04-10 23:53:00                      0                      0   \n",
       "\n",
       "                     P-JUS-CKGL__is_missing  T-JUS-CKGL__is_missing  \\\n",
       "timestamp                                                             \n",
       "2018-04-10 23:49:00                       1                       1   \n",
       "2018-04-10 23:50:00                       1                       1   \n",
       "2018-04-10 23:51:00                       1                       1   \n",
       "2018-04-10 23:52:00                       1                       1   \n",
       "2018-04-10 23:53:00                       1                       1   \n",
       "\n",
       "                     QGL__is_missing  id  \n",
       "timestamp                                 \n",
       "2018-04-10 23:49:00                1   0  \n",
       "2018-04-10 23:50:00                1   0  \n",
       "2018-04-10 23:51:00                1   0  \n",
       "2018-04-10 23:52:00                1   0  \n",
       "2018-04-10 23:53:00                1   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "      <th>P-PDG__is_missing</th>\n",
       "      <th>P-TPT__is_missing</th>\n",
       "      <th>T-TPT__is_missing</th>\n",
       "      <th>P-MON-CKP__is_missing</th>\n",
       "      <th>T-JUS-CKP__is_missing</th>\n",
       "      <th>P-JUS-CKGL__is_missing</th>\n",
       "      <th>T-JUS-CKGL__is_missing</th>\n",
       "      <th>QGL__is_missing</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-12 07:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16647840.0</td>\n",
       "      <td>118.0997</td>\n",
       "      <td>7360490.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>3931823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12 07:01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16643050.0</td>\n",
       "      <td>118.1049</td>\n",
       "      <td>7356511.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>3933994.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12 07:02:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16638260.0</td>\n",
       "      <td>118.0912</td>\n",
       "      <td>7352533.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>3936164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12 07:03:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16644150.0</td>\n",
       "      <td>118.1107</td>\n",
       "      <td>7348554.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>3938334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12 07:04:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16650800.0</td>\n",
       "      <td>118.1049</td>\n",
       "      <td>7435900.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>3940504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     P-PDG       P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  \\\n",
       "timestamp                                                                \n",
       "2013-12-12 07:00:00    0.0  16647840.0  118.0997  7360490.0   173.0961   \n",
       "2013-12-12 07:01:00    0.0  16643050.0  118.1049  7356511.0   173.0961   \n",
       "2013-12-12 07:02:00    0.0  16638260.0  118.0912  7352533.0   173.0961   \n",
       "2013-12-12 07:03:00    0.0  16644150.0  118.1107  7348554.0   173.0961   \n",
       "2013-12-12 07:04:00    0.0  16650800.0  118.1049  7435900.0   173.0961   \n",
       "\n",
       "                     P-JUS-CKGL  T-JUS-CKGL  QGL  class  P-PDG__is_missing  \\\n",
       "timestamp                                                                    \n",
       "2013-12-12 07:00:00   3931823.0         0.0  0.0      0                  0   \n",
       "2013-12-12 07:01:00   3933994.0         0.0  0.0      0                  0   \n",
       "2013-12-12 07:02:00   3936164.0         0.0  0.0      0                  0   \n",
       "2013-12-12 07:03:00   3938334.0         0.0  0.0      0                  0   \n",
       "2013-12-12 07:04:00   3940504.0         0.0  0.0      0                  0   \n",
       "\n",
       "                     P-TPT__is_missing  T-TPT__is_missing  \\\n",
       "timestamp                                                   \n",
       "2013-12-12 07:00:00                  0                  0   \n",
       "2013-12-12 07:01:00                  0                  0   \n",
       "2013-12-12 07:02:00                  0                  0   \n",
       "2013-12-12 07:03:00                  0                  0   \n",
       "2013-12-12 07:04:00                  0                  0   \n",
       "\n",
       "                     P-MON-CKP__is_missing  T-JUS-CKP__is_missing  \\\n",
       "timestamp                                                           \n",
       "2013-12-12 07:00:00                      0                      0   \n",
       "2013-12-12 07:01:00                      0                      0   \n",
       "2013-12-12 07:02:00                      0                      0   \n",
       "2013-12-12 07:03:00                      0                      0   \n",
       "2013-12-12 07:04:00                      0                      0   \n",
       "\n",
       "                     P-JUS-CKGL__is_missing  T-JUS-CKGL__is_missing  \\\n",
       "timestamp                                                             \n",
       "2013-12-12 07:00:00                       0                       1   \n",
       "2013-12-12 07:01:00                       0                       1   \n",
       "2013-12-12 07:02:00                       0                       1   \n",
       "2013-12-12 07:03:00                       0                       1   \n",
       "2013-12-12 07:04:00                       0                       1   \n",
       "\n",
       "                     QGL__is_missing   id  \n",
       "timestamp                                  \n",
       "2013-12-12 07:00:00                0  562  \n",
       "2013-12-12 07:01:00                0  562  \n",
       "2013-12-12 07:02:00                0  562  \n",
       "2013-12-12 07:03:00                0  562  \n",
       "2013-12-12 07:04:00                0  562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = load_all_data( \n",
    "    addresses=addresses_train, \n",
    "    instances=instances_train, \n",
    "    events=events_train, \n",
    "    ids=ids_train,\n",
    "    positive_event='3',\n",
    "    periods_undersample=60\n",
    ")\n",
    "display(df_train.head())\n",
    "\n",
    "df_test = load_all_data( \n",
    "    addresses=addresses_test, \n",
    "    instances=instances_test, \n",
    "    events=events, \n",
    "    ids=ids_test,\n",
    "    positive_event='3',\n",
    "    periods_undersample=60 \n",
    ")\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://glossary.slb.com/en/search#q=bsw&sort=relevancy\n",
    "\n",
    "create hyperlink \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vfm_3wdataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
